<!DOCTYPE html>
<html>

<head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-167680016-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-167680016-1');
</script>

    <link href="https://fonts.googleapis.com/css?family=EB+Garamond&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
    <link type="text/css" href="style.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Cormorant+Garamond&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Libre+Caslon+Text&display=swap" rel="stylesheet">


    <title>
        Phillip Hintikka Kieval
    </title>
</head>

<body>


<div id="title">
        <a href="index.html">
            <center>
                <h1>Phillip Hintikka Kieval</h1>
            </center>
        </a>
    </div>
    <div id="menu">

         <a href="index.html">
            <div class="menu-links" id="index">
                <p>About</p>
            </div>
        </a>
        
        <a href="research.html">
            <div class="menu-links" id="research">
                <p>Research</p>
            </div>
        </a>
        <a href="teaching.html">
            <div class="menu-links" id="teaching">
                <p>Teaching</p>
            </div>
        </a>
        <a href="contact.html">
            <div class="menu-links" id="contact">
                <p>Contact</p>
            </div>
        </a>
       <a target = "_blank" href="KievalCV.pdf">
        
            <div class="menu-links" id="cv">
                <p>CV</p>
            </div>
        </a>
    </div>
    
 

 <section class="section1">



   <table> 

    <tr>

    <td class="course-name">Research Interests</td>
    <td class="course-description">

        <p>
      My primary research interests concern the philosophy of machine learning and its intersections with cognitive science, philosophy of neuroscience, philosophy of biology, general philosophy of science, ethics, and public policy. I am also interested in social and normative epistemology, pragmatism, and feminist philosophy.

        </p>
    </td>
     <td class="research-pics">
<div id="deep-learning" class="research-circles"></div>
     </td>
</tr>
</table>

 <table> 

    <tr>

    <td class="course-name">Deep Learning</td>
    <td class="course-description">

        <p>
      My most recent work focuses on the structure and content of representations in deep neural networks. State-of-the-art machine learning systems are ubiquitous in modern life. Deep neural networks exhibit a remarkable level of predictive success worthy of the popular label of artificial intelligence (AI). These systems find applications in everything from automated decision assistance in medicine and criminal justice to playing board games like chess and Go. Our epistemic networks are increasingly intertwined with machine learning algorithms, and scientists rely on them in complex computational models. However, deep learning systems are opaque in ways that make explaining their capacities intractable. Philosophers of science are uniquely positioned to investigate critical questions concerning the widespread implementation of machine learning systems. How can deep neural networks teach us about the brain? How do these models generate explanations in science? To what extent does science demand transparency in AI? How should rapid technological advancements in AI inform public policy? How can we promote more humane and egalitarian implementations of AI in public life? I am optimistic that we can glean some answers to these questions by investigating how deep learning systems learn and exploit representations.

        </p>
    </td>
     <td class="research-pics">
<div id="alphafold" class="research-circles"></div>
     </td>
</tr>
</table>

   <table> 

    <tr>

    <td class="course-name">Works in Progress</td>
    <td class="course-description">

    <p> <h3>Deepening Representations (Under review)</i></h3> 


    In an age of explosive progress in Artificial Intelligence (AI) research, understanding how information is encoded in abstract representations in machine learning (ML) systems is crucial for understanding their intelligent capacities and their utility as scientific instruments. This imperative suggests revisiting connection- ism, a view that explains intelligence in terms of domain-general capacities to learn abstract representations from low-level perceptual inputs. Renewed interest in connectionism within the philosophy of science points out that artificial neural networks can be understood as idealized, multilevel models capable of generating explanatory insight into the mechanisms underlying cognition, and mounting empirical evidence suggests that these networks are useful tools for prediciting neural activity in the primate brain. Yet, the predominance of ML-based techniques in cognitive neuroscience raises a host of philosophical and methodological concerns. Given the messiness of neural activity, modelers must make choices about how to structure their raw data to make inferences about encoded representations. This leads to a set of standard methodological assumptions about when abstraction is appropriate in neuroscientific practice. But when made uncritically these choices threaten to bias conclusions about phenomena drawn from data. Contact between the practices of multivariate pattern analysis (MVPA) and philosophy of science can help to illuminate the conditions under which we can safely rely on artificial neural networks (ANNs) to generate sound transitions from data to phenomena. This paper considers a specific technique for MVPA called representational similarity analysis (RSA). I develop a theoretically-informed account of RSA that draws on early connectionist research and work on idealization in the philosophy of science. By bringing a philosophical account of cognitive modelling in conversation with RSA, this paper clarifies the practices of neuroscientists and provides a generalizable framework for using ANNs to study cogntivie mechanisms in the brain.

    <li> Draft available upon request.



    </p>

</tr>
</table>

   <table> 

    <tr>

    <td class="course-name"> </td>
    <td class="course-description">

    <p>
        <h3>Permission to Believe at Will </i></h3>   

       According to doxastic involuntarism, we cannot believe at will. In this paper, I argue that permissivism, the view that, at times, there is more than one way to respond rationally to a given body of evidence, is consistent with doxastic involuntarism. Blake Roeber (2019a,b) argues that, since permissive situations are possible, cognitively healthy agents can believe at will. However, Roeber (2019b) fails to distinguish between two different arguments for voluntarism, both of which can be shown to fail by proper attention to different accounts of permissivism. Roeber considers a generic treatment of permissivism, but key premises in both arguments depend on different, more particular notions of permissivism. Attending to these differences reveals that the inference from permissivism to voluntarism to be unwarranted.  
     
      <ul><li><a target = "_blank" href ="Kieval - Permission to Believe at Will [draft].pdf">Click here for draft</a></ul> 
        



        </p>
    </td>

   

</tr>
</table>
    
 
 </section>



    
    
</body>

</html>